[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Here you’ll find my thoughts, tutorials, and updates about my work.\n\n\n\n\n\nDate: January 1, 2024\nA brief description of the blog post content.\n\n\n\nDate: December 15, 2023\nA brief description of the blog post content.\n\n\n\n\n\n\nResearch Updates\nTutorials\nProject Updates\nGeneral Thoughts\n\n\n\n\nStay updated with my latest posts by following me on Twitter or subscribing to the RSS feed."
  },
  {
    "objectID": "blog/index.html#recent-posts",
    "href": "blog/index.html#recent-posts",
    "title": "Blog",
    "section": "",
    "text": "Date: January 1, 2024\nA brief description of the blog post content.\n\n\n\nDate: December 15, 2023\nA brief description of the blog post content."
  },
  {
    "objectID": "blog/index.html#categories",
    "href": "blog/index.html#categories",
    "title": "Blog",
    "section": "",
    "text": "Research Updates\nTutorials\nProject Updates\nGeneral Thoughts"
  },
  {
    "objectID": "blog/index.html#subscribe",
    "href": "blog/index.html#subscribe",
    "title": "Blog",
    "section": "",
    "text": "Stay updated with my latest posts by following me on Twitter or subscribing to the RSS feed."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "📝 Blog and Professional Channels",
    "section": "",
    "text": "Welcome! Here you can find my professional writings, research updates, and project showcases across different platforms:\n\n📰 Medium — Articles and insights on data science, AI, and technology.  🧑‍💻 GitHub — Code repositories, project demos, and practical implementations.  🎓 Google Scholar — Academic publications and research contributions.  🔗 LinkedIn — Connect and follow my professional updates. \nThank you for your time!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Katie B",
    "section": "",
    "text": "Welcome to my profile! \n\n\n\n\n\nHello, I’m Katie Baronowski  🎓 PhD Student in Information Science with a focus on integrating the technological with the original biological sensors, using drones and AI to enhance the work of detection dogs. 🏫 State University of New York at Albany (SUNY Albany) 📍 New York, USA \n🔬 Research Interests:\n- Human-Computer Interaction\n- Improving detection capabilities - Human and Animal Behavior and Cognition"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Katie B",
    "section": "",
    "text": "Welcome to my profile! \n\n\n\n\n\nHello, I’m Katie Baronowski  🎓 PhD Student in Information Science with a focus on integrating the technological with the original biological sensors, using drones and AI to enhance the work of detection dogs. 🏫 State University of New York at Albany (SUNY Albany) 📍 New York, USA \n🔬 Research Interests:\n- Human-Computer Interaction\n- Improving detection capabilities - Human and Animal Behavior and Cognition"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Katie B",
    "section": "Education",
    "text": "Education\n🎓 PhD Student in Information Science, State University of New York at Albany, USA (Aug 2024 – Present)  - Cumulative GPA: 4.00/4.00.  - Primary Specialization: Information for Risk in Emergency Management and Security - Secondary Specialization: Information in Organizational Environments\n🎓 Bachlelor of Technology in Canine Training and Management and Bachelor of Science in Applied Psychology, SUNY Cobleskill, USA (Aug 2020 – May 2024)  - Outstanding Student in Psychology 2024.  - Student Leadership Award 2024.  - Honors Capstone: Canine discrimination of the enantiomers of carvone."
  },
  {
    "objectID": "index.html#research-overview",
    "href": "index.html#research-overview",
    "title": "Katie B",
    "section": "Research Overview",
    "text": "Research Overview\nMy research explores the intersection of Technological and the Biological, developing AI algorithms that enhance predication of target odor and the efficacy of search and rescue."
  },
  {
    "objectID": "index.html#recent-updates",
    "href": "index.html#recent-updates",
    "title": "Katie B",
    "section": "Recent Updates",
    "text": "Recent Updates\n🏆 Received AEOP Fellowship.  🚀 Internship at the Grants, Research, and Opportunites Workforce in the State University of New York system for summer 2025. 📜 Attending INTERSECT bootcamp at Princeton New Jersey (July 2025).  ✍️ First-author manuscript on detection dogs.  🚀 Mentoring undergraduate students in the Mobile Sensor Lab at SUNY Albany."
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "Katie B",
    "section": "Quick Links",
    "text": "Quick Links\n🔬 Research  🎓 Academic Experience  💼 Professional Experience  🛠️ Practical Projects  📝 Blog  📄 CV"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Katie B",
    "section": "Contact",
    "text": "Contact\n📧 kbaronowski@albany.edu \nThank you!"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "🔬 Research",
    "section": "",
    "text": "Information Science student, with a focus on human-computer interaction, information behavior, and utilizing technology to enhance detection K9-handler teams.\n\n🛡️ My work explores: - 🔒 Detection dogs - 🔐 Information Behavior - 💧 Human-Computer Interaction\nto improve detection capabilites and response during emergencies and disasters."
  },
  {
    "objectID": "research.html#published",
    "href": "research.html#published",
    "title": "🔬 Research",
    "section": "📖 Published",
    "text": "📖 Published"
  },
  {
    "objectID": "research.html#forthcoming-submitted",
    "href": "research.html#forthcoming-submitted",
    "title": "🔬 Research",
    "section": "📝 Forthcoming (Submitted)",
    "text": "📝 Forthcoming (Submitted)\n\nKatie Baronowski, Thomas Sadekoski, Kathryn Miller, Brian Hefferon, Eric Best, Mark Cornwell, Jennifer Essler. Round Goby Detection Dogs"
  },
  {
    "objectID": "academic.html",
    "href": "academic.html",
    "title": "🏫 Academic Experience",
    "section": "",
    "text": "🎓 Education\n\n\nPh.D. Student in Information Science Aug 2024 – Present 🏫 State University of New York at Albany, NY, USA 🔬 Research Topic: Trustworthy Machine Learning and AI through the Lens of Privacy and Security 📊 GPA: 4.00/4.00\n\n\nMaster in Analytics, Applied Machine Intelligence Aug 2021 – Jul 2023 🏫 Northeastern University, MA, USA 📝 Thesis: Improving Safety through the Integration of Multi-sensor Fusion and Deep Learning-based Object Detection 📊 GPA: 4.00/4.00\n\n\n\n\n👨‍🏫 Teaching & Student Mentorship Experience\n\n\nIntern Mentor – State University of New York at Albany Jan 2024 – Present 🤝 Mentored undergraduate interns on the project Transforming Large Language Model Alignment: Automating Reference Data Generation through Explainable AI.\n\n\nTeaching Assistant – Northeastern University Aug 2021 – Dec 2021 📚 Course: ALY 6010 - Introduction to Statistics and Probability\n\n\n\n\n🏆 Honors & Awards\n\n🥈 Second Prize, Best Poster at NTIR 2025 Apr 2025  🎓 Valedictorian, Master in Analytics, Northeastern University Jul 2023  🏅 Hackathon Winner – OCR and Language Model for Form Autofill, Definity Financial Feb 2023  🎯 Top 20 Finalist – VinUniversity Global Case Competition Dec 2021  💰 Merit-based Scholarship, Foreign Trade University 2013 & 2014  🌟 Talent Incubation Scholarship, Coca-Cola Vietnam & Thanh Nien News Nov 2013  🌍 Ambassador – Exchange Participant, AIESEC Indonesia Jun–Aug 2013 \n\n\n\n🤝 Professional Services\n\n🎪 Organizer committee, NTIR Conference - Where Innovation Meets Information 2025 April 2025  📖 Journal Reviewer, Journal of Combinatorial Optimization 2025 Jan–May 2025  📝 Conference Reviewer, Computational Data and Social Networks 2024 Oct–Dec 2024"
  },
  {
    "objectID": "professional.html",
    "href": "professional.html",
    "title": "💼 Professional Experience",
    "section": "",
    "text": "Machine Learning Content Engineer (Freelancer – Partner Program) Nov 2022 – Present 🏢 A Medium Corporation, CA, USA 📝 Translate complex machine learning topics, especially in NLP, into accessible and insightful content for a diverse audience.\n\n\nSenior Data Scientist (Remote Full Time) Oct 2023 – May 2024 🏢 Hitachi Vantara Corporation, CA, USA - 🤖 Applied deep learning to deploy predictive models across healthcare, retail, manufacturing, and finance. - 🧠 Enhanced financial text analytics using advanced NLP techniques. - 📈 Built causal time series models to improve retail supply chain forecasting.\n\n\nData Scientist and Modeling (Co-op) Jan 2023 – May 2023 🏢 Definity Financial, ON, Canada - 🖼️ Prepared image, text, and tabular data on car accidents for predictive modeling. - 🚀 Built and deployed four models for underwriting, actuary, and claims with reproducible pipelines.\n\n\nSenior Manager, Category Management Sep 2020 – Aug 2021 🏢 Alibaba Group – Lazada E-commerce, HCMC, Vietnam - 🔍 Collaborated with the Data Science team to evaluate search exposure and sales drivers using text mining and A/B testing techniques. - 📊 Conducted hypothesis-driven ad-hoc analysis to address business-critical operational queries."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "🚀 Practical Projects",
    "section": "",
    "text": "This proof of principle project was designed to test the feasibility of round goby detection dogs, to identify of the invasion fronts in the tributaries of the Mohawk River in collaboration with USGS."
  },
  {
    "objectID": "projects.html#i.-detection-dogs",
    "href": "projects.html#i.-detection-dogs",
    "title": "🚀 Practical Projects",
    "section": "",
    "text": "This proof of principle project was designed to test the feasibility of round goby detection dogs, to identify of the invasion fronts in the tributaries of the Mohawk River in collaboration with USGS."
  },
  {
    "objectID": "projects copy.html",
    "href": "projects copy.html",
    "title": "Practical Projects",
    "section": "",
    "text": "This project is designed to identify unsafe holes on construction sites, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\n🛠️ Workflow and Tech Stack: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\n🔬 Techniques and Strategies: Transfer learning, Hyperparameter tunning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n\n      \nView project on Github\nView project on Google Colab\n\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n\n🔍 Project Highlights: - Utilizes Llama Index for efficient token management and in-context learning. - Extracts relevant customer support conversations from Twitter using a Kaggle dataset. - Trains a chatbot using language models like ChatGPT and Hugging Face. - Creates a user-friendly interface with Gradio for easy customer interaction. - Revolutionizes customer support by combining AI and real customer interactions.\n\\ \\ \\ \\ \\\nView project on Github"
  },
  {
    "objectID": "projects copy.html#i.-deep-learning-and-ai",
    "href": "projects copy.html#i.-deep-learning-and-ai",
    "title": "Practical Projects",
    "section": "",
    "text": "This project is designed to identify unsafe holes on construction sites, helping to ensure the well-being of workers and the integrity of job sites. When combined with a Personal Protective Equipment (PPE) detection model, it forms a robust safety monitoring system deployed on Jetson-based edge inference systems.\n🛠️ Workflow and Tech Stack: To train this model, I adopted an Iterative Training Process. Data preparation and deployment were accomplished with Roboflow, while model customization took place in Google Colab.\n🔬 Techniques and Strategies: Transfer learning, Hyperparameter tunning, Multiple Deep Learning Algorithms to train and compare (YOLO, DETR, RCNN, COCO, UNet), Iterative training and Model Refinement.\n\n\n      \nView project on Github\nView project on Google Colab\n\n\n\nThis project is a deep dive into the world of AI-driven customer service chatbots, enhanced by the power of in-context learning. We leverage the Llama Index and Language Model API to create a chatbot that understands and responds to customer inquiries effectively, transforming the way businesses provide support.\n\n\n🔍 Project Highlights: - Utilizes Llama Index for efficient token management and in-context learning. - Extracts relevant customer support conversations from Twitter using a Kaggle dataset. - Trains a chatbot using language models like ChatGPT and Hugging Face. - Creates a user-friendly interface with Gradio for easy customer interaction. - Revolutionizes customer support by combining AI and real customer interactions.\n\\ \\ \\ \\ \\\nView project on Github"
  },
  {
    "objectID": "projects copy.html#ii.-data-science-and-machine-learning",
    "href": "projects copy.html#ii.-data-science-and-machine-learning",
    "title": "Practical Projects",
    "section": "📘 II. Data Science and Machine Learning",
    "text": "📘 II. Data Science and Machine Learning\n\n✨ Dune Series Network Analysis and Community Detection\nThis project delves into the captivating “Dune” book series by Frank Herbert using advanced data analysis techniques. By harnessing natural language processing and network science, we uncover the intricate web of character relationships and communities within this iconic science fiction universe.\n🔍 Project Highlights: - Utilizes Named Entity Recognition (NER) to extract character and location names. - Constructs a character relationship graph using NetworkX. - Applies the Louvain Algorithm for community detection. - Evaluates community structure with modularity analysis and centrality measures.\n\n\n\nDune Network Analysis\n\n\n    \nView project on Github\n\n\n✨ CV and Job Matching\nThis application predicts the matching percentage of a candidate’s resume to a job posting. It utilizes the Doc2Vec model, which represents job descriptions and resumes as numerical vectors. Doc2Vec combines the Continuous Bag-of-Words (CBOW) and Skip-Gram techniques to efficiently compare and calculate similarity between textual documents. The trained model can be easily deployed and hosted online (Azure), providing a convenient solution for matching CVs with job postings.\nNote: The algorithm serves as the first step in a use-case scenario where a company receives multiple job applications for various job postings. The second step involves employing the modified Gale-Shapley algorithm to index candidates for each job and select the best match.\n\n     \nView code on Github\n\n\n✨ Sales forecasting using SARIMAX (Industry best practices)\nThis project follows industry best practices to address time series problems and involves key steps such as checking for stationarity, data transformation, decomposing models into components, anomaly detection, white noise checking, identifying orders, and performance measurement. The goal is to provide accurate sales forecasts for Walmart superstore and facilitate data-driven decisions.\n\n      \nView code on Github\n\n\n✨ Automated Text Data Extraction and Form Filling System\nThis project introduces an innovative solution for automating text data extraction and form filling, aiming to streamline data processing in the digital age. Leveraging a combination of OCR, natural language processing, and rule-based approaches, it offers an efficient way to extract information from unstructured text and populate forms accurately, saving time and reducing errors.\n🔍 Project Highlights: - Incorporates Optical Character Recognition (OCR) for text recognition. - Employs Named Entity Recognition (NER) to identify and capture entities. - Utilizes regular expressions for structured data extraction. - Integrates rule-based approaches for specific data patterns. - Offers a hybrid approach combining multiple methods for robust extraction. - Harnesses large language models (ChatGPT API) for context-aware data extraction.\n\n\n\nProject Preview\n\n\n     \nView project on Github\n\n\n✨ Explainable Machine Learning - Understand the Black-Box\nInterpretable Machine Learning (ML) is a critical aspect of advancing the use of machine learning in various fields. Many black box models hinder ML’s adoption due to their lack of transparency and interpretability. The Jupyter Notebook in this repository includes the following sections:\n\nPDP for Bike Rent Data: Demonstrates how to use Partial Dependence Plots for interpreting a machine learning model using bike rental data. It explains how the model works and how to interpret PDP plots.\n\n\n\n\nPDP\n\n\n\nLIME for Image Classification: Illustrates the use of LIME to explain an image classification model. It provides insights into the model’s predictions and how to interpret LIME plots.\nSHAP for Breast Cancer Classification: Shows how to use SHAP values for interpreting a breast cancer classification model. It describes the model’s behavior and how to interpret SHAP plots.\n\n\n\nComparative Analysis: Offers a comparative analysis of PDP, LIME, and SHAP, summarizing the strengths and weaknesses of each method for model interpretability.\n\n   \nView project on Github"
  },
  {
    "objectID": "projects copy.html#iii.-mlops",
    "href": "projects copy.html#iii.-mlops",
    "title": "Practical Projects",
    "section": "📘 III. MLOPs",
    "text": "📘 III. MLOPs\n\n✨ Salary Prediction Application\nThis application predicts the salary of software engineers based on key pieces of information. It features two sections: a prediction page for salary prediction and an exploration page for EDA insights from the dataset. The predictions are generated using an XGBoost model, while the web app is built on Streamlit framework. To ensure the reproducibility, virtual environments are utilized on local hosts and contained by Docker. This app is deployed on GCP as well. A video guide on how to use the application is also available.\n\n\n     \nView code on Github"
  },
  {
    "objectID": "projects copy.html#iv.-data-analysis-and-business-intelligence",
    "href": "projects copy.html#iv.-data-analysis-and-business-intelligence",
    "title": "Practical Projects",
    "section": "📘 IV. Data Analysis and Business Intelligence",
    "text": "📘 IV. Data Analysis and Business Intelligence\n\n✨ Walmart Ecommerce Dashboard Project\nThis project showcases the creation of an interactive Ecommerce Dashboard for Walmart using Power BI. The goal was to analyze and visualize key performance indicators (KPIs) to gain insights into sales, revenue, customer behavior, and more. The project followed a structured approach, encompassing defining KPIs, working with raw data in SQL Server for efficient manipulation, building SQL queries for validation, connecting Power BI for visualization, and utilizing Power Query for data cleaning. By incorporating calculated measures and time intelligence functions, the dashboard provides a comprehensive overview of Walmart’s ecommerce operations. The project follows a standard pipeline in BI and DA, starting from database to transformation and visualization.\n\n\n  \nView code on Github\n\n\n✨ CO2 Emission Data Visualization Dashboard\nThis interactive dashboard project empowers users to explore and visualize carbon dioxide (CO2) emissions data from Our World in Data. It leverages cutting-edge Python libraries, including Panel, Hvplot, and GeoPandas, to create an intuitive and informative platform for analyzing CO2 emissions worldwide. The dashboard enables users to filter emissions data by year and country, compare emissions trends through scatterplots, and visualize geographical variations on a map. It serves as a valuable tool for gaining insights into the primary driver of global climate change and fostering data-driven discussions around emissions reduction.\n\n\n   \nView code on Github"
  }
]